# ETL Project - README

## Project Overview

This project demonstrates a complete **ETL (Extract, Transform, Load)** pipeline. We extracted raw data from the **Kaggle API**, performed data cleaning and transformation using **Python**, analyzed the processed data using **SQL**, and visualized insights through **Power BI**.

## Key Components

### 1. **Data Extraction**
   - **Source**: Data was extracted using the **Kaggle API**.
   - **Tools**: Python was used to interact with the API, download datasets, and manage file paths.

### 2. **Data Cleaning & Transformation**
   - **Language**: Python
   - **Libraries Used**:
     - `pandas` for data manipulation (handling missing values, renaming columns, etc.)
   - **Tasks**:
     - Removal of null values and duplicates.
     - Transformation of date formats.
     - Standardization of categorical variables and numeric columns for consistency.

### 3. **Data Analysis**
   - **Language**: SQL
   - **Database**: The cleaned and transformed data was loaded into a SQL database for analysis.
   - **Key Queries**:
     - Aggregation of key metrics.
     - Complex queries involving groupings, and subqueries to extract insights.

### 4. **Data Visualization**
   - **Tool**: Power BI
   - **Visualizations Created**:
     - Charts and graphs to represent trends, distributions, and patterns.
     - Dashboards with KPIs and interactive features for deeper insights.

## Setup Instructions

### Prerequisites
- Python 3.x
- Kaggle API key (ensure it's configured in your environment)
- SQL database setup (MySQL, PostgreSQL, etc.)
- Power BI Desktop (for data visualization)


## Contact
For any questions or clarifications, feel free to reach out at riyabattu84955@gmail.com 
